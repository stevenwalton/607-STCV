%\begin{frame}
%\frametitle{Outline}
%    \begin{itemize}
%        \item What Are Generators?
%    \end{itemize}
%\end{frame}

\begin{frame}
    \frametitle{Generators}
    \begin{columns}
    \begin{column}{0.48\paperwidth}
        \begin{itemize}
            \item<1->Suppose that we have some probability space $S$.
            \item<2->$S$ has two variables $X$ (instances) and $Y$ (labels) that
                represent cats and dogs.
            \item<3->Often we want to find a boundary between different types of
                data within a sample space. (Discrimitive Model)
            \item<4->We might instead want to \textit{sample} from this space
                and see what images are here.
            \item<5->Typically we'll only work with a single classification.
        \end{itemize}
    \end{column}
    \begin{column}{0.48\textwidth}
        \includegraphics<1>[width=\textwidth]{SampleSpace_Empty.png}
        \includegraphics<2>[width=\textwidth]{SampleSpace.png}
        \includegraphics<3>[width=\textwidth]{SampleSpace_Classification.png}
        \includegraphics<4>[width=\textwidth]{SampleSpace_Generation.png}
        \includegraphics<5>[width=\textwidth]{SampleSpace_Cats.png}
    \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{Generators}
    \begin{itemize}
        \item In a Discriminitive model we learn a conditional probability
            $P(Y|X)$ (predict the label given an image).
        \item In a Generative model we learn to sample for p(x)
            (produce an image).
        \item<2> In reality we learn $p_\theta(\hat{x})$ from $p_{true}(x)$
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{But Why?}
    \includegraphics<1>[width=\textwidth]{ButWhy.jpg}
\end{frame}

\begin{frame}
    \frametitle{But Why?}
    \begin{itemize}
        \item<1-> We can create images that don't exist.
        \item<2-> We can create new datasets.
        \item<3-> We can upscale images/videos.
        \item<4-> We can lean latent variables.
        \item<5-> We can uncover biases.
        \item<6-> And so much more!
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{But Why?: Generate Images}
    \begin{columns}
        \begin{column}{0.48\paperwidth}
            \begin{itemize}
                \item We can generate cats that don't exist.
                \item Helps create new data within a dataset.
                \item Can create fake characters/animals/scenes that don't exist
                    in real life but look realistic (art).
            \end{itemize}
        \end{column}
        \begin{column}{0.48\paperwidth}
            \includegraphics[width=\textwidth]{TCDNE.png}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{But Why?: Upscaling}
    \begin{columns}
        \begin{column}{0.48\paperwidth}
            \begin{itemize}
                \item We can take lossy images and produce higher quality
                    images.
                \item We can also take smaller images and make them larger.
                \item Helpful in compression.
            \end{itemize}
        \end{column}
        \begin{column}{0.48\paperwidth}
            \includegraphics[width=\textwidth]{Upscaling.jpg}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{But Why?: Learn Latent Variables}
    \begin{columns}
        \begin{column}{0.48\paperwidth}
            \begin{itemize}
                \item We can learn the different latent variables in a dataset.
                \item For example we can learn how to make someone old!
                \item We could also use this as a form of compression
                    (autoencoders)
            \end{itemize}
        \end{column}
        \begin{column}{0.48\paperwidth}
            \includegraphics[width=\textwidth]{latent.jpg}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{But Why?: Uncovering Bias}
    \begin{columns}
        \begin{column}{0.48\paperwidth}
            \begin{itemize}
                \item<1-> We have a dataset of faces.
                \item<2-> Might have some distribution, let's say...
                \item<3-> Most of the faces fit in the main part of the
                    distribution.
                \item<4-> We have outliers in the dataset.
                \item<5-> We can now adjust our dataset or potentially generate
                    new images for a classifier if we can't fix the distribution
                    (might not be logistically possible).
            \end{itemize}
        \end{column}
        \begin{column}{0.48\paperwidth}
            \includegraphics<1>[width=\textwidth]{Faces.png}
            \includegraphics<2>[width=\textwidth]{Faces_Distribution.png}
            \includegraphics<3>[width=\textwidth]{Faces_MainDistrib.png}
            \includegraphics<4->[width=\textwidth]{Faces_Tail.png}
        \end{column}
    \end{columns}
\end{frame}


\begin{frame}
    \frametitle{Taxonomy of Generators}
    \includegraphics[width=\textwidth]{taxonomy.png}
    \null\hfill \tiny{source: ian goodfellow}
\end{frame}

\begin{frame}
    \frametitle{Taxonomy of Generators: Implicit Density}
    \begin{columns}
        \begin{column}{0.48\paperwidth}
            \begin{itemize}
                \item We want to learn a stochastic procedure to generate data. 
                \item We learn liklihood-free.
            \end{itemize}
        \end{column}
        \begin{column}{0.48\paperwidth}
            \includegraphics[width=\textwidth]{taxonomy_Implicit.png}
            \null\hfill \tiny{source: ian goodfellow}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{This X Does Not Exist}
    \vspace{-1em}
    \begin{figure}
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{tpdne.jpg}
            \caption{This Person Does Not Exist (StyleGAN2)}
        \end{subfigure}
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{tcdne.jpg}
            \caption{This Cat Does Not Exist (StyleGAN)}
        \end{subfigure}
        \begin{subfigure}{0.5\textwidth}
            \includegraphics[width=\textwidth]{twdne.png}
            \caption{This Anime Does Not Exist (StyleGAN2 + GPT-3)}
        \end{subfigure}
    \end{figure}
\end{frame}

\begin{frame}
    \frametitle{Generative Adversarial Networks}
    \includegraphics[width=\textwidth]{AC-GAN.png}
\end{frame}

\begin{frame}
    \frametitle{Generative Adversarial Networks}
    \center\includegraphics[height=0.75\textheight]{GAN.png}
\end{frame}

\begin{frame}
    \frametitle{Generative Adversarial Networks}
    \center\includegraphics[height=0.75\textheight]{GAN-as-AC.png}
\end{frame}

\begin{frame}
    \frametitle{Generative Adversarial Networks}
    \begin{itemize}
        \item Send noise into Generator.
        \item Send generated image and real images into Discriminator.
        \item Play mini-max game teaching the Generator to fool the
            Discriminator.
        \item When fake image can adaquately fool (a well trained) discriminator
            we produce quality images. 
        \item<2-> In practice we train D, then G then repeat. 
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{But Why Is This Implicit?}
    \begin{itemize}
        \item We didn't learn a density function.
        \item We just focus on generating samples.
        \item Don't have an (easy) smooth transition between latent variables.
        \item Likelihood is not tractable.
        \item "We're training them to memorize, not generalize" - Ian Goodfellow
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Latent Space}
    \includegraphics<1>[height=0.75\textheight]{oregonTopo.jpg}
    \includegraphics<2>[height=0.75\textheight]{oregonTopo1.jpg}
    \includegraphics<3>[height=0.75\textheight]{oregonTopo2.jpg}
    \includegraphics<4>[height=0.75\textheight]{oregonTopo3.jpg}
    \includegraphics<5>[height=0.75\textheight]{oregonTopo4.jpg}
\end{frame}

\begin{frame}
    \frametitle{Latent Space}
    \vspace{-1.25em}
    \center\footnotesize{TSNE visualization of vanilla GAN latent space. }
    \center\includegraphics[height=0.70\textheight]{GANLatent.png}
    \\
    \tiny{Image from ClusterGAN paper which works on resolving this
    issue}
\end{frame}

\begin{frame}
    \frametitle{So Why Use GANs?}
    \begin{itemize}
        \item Because they are quick.
        \item They produce high quality images.
        \item Can still do many tasks.
        \item They're well researched.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Taxonomy of Generators: Explicit Density}
    \begin{columns}
        \begin{column}{0.48\paperwidth}
            \begin{itemize}
                \item We want to learn a distribution of
                    data. 
                \item We assume some prior about the distribution of the data. 
                \item We learn the log-liklihood of the function $\log
                    p_\theta(x)$
            \end{itemize}
        \end{column}
        \begin{column}{0.48\paperwidth}
            \includegraphics[width=\textwidth]{taxonomy_Explicit.png}
            \null\hfill \tiny{source: ian goodfellow}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{AutoEncoders}
    \includegraphics[width=\textwidth]{AutoEncoder.png}
\end{frame}


\begin{frame}
    \frametitle{AutoEncoders}
    \begin{columns}
        \begin{column}{0.48\paperwidth}
            \begin{itemize}
                \item Want to learn latent variable $z$ from $x$. $\mathbb{R}^n
                    \mapsto \mathbb{R}^m$ where $m<n$
                \item Compressed representation of the data.
                \item Since we don't have training data for z, we construct a
                    decoder to do unsupervised learning.
            \end{itemize}
        \end{column}
        \begin{column}{0.48\paperwidth}
            \includegraphics[width=\textwidth]{AutoEncoder.png}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{AutoEncoders}
    \begin{columns}
        \begin{column}{0.48\paperwidth}
            \begin{itemize}
                \item<1-> Want to take $x$ and produce $\hat{x}$
                \item<2-> Sample $x$ from dataset and encode to latent space
                    $z$.
                \item<3-> Decode to sample from $z$ and generate $\hat{x}$
                \item<4-> Regularize $||x-\hat{x}||^2$
                \item<5-> Gives us a unsupervised training.
            \end{itemize}
        \end{column}
        \begin{column}{0.48\paperwidth}
            \includegraphics<1>[width=\textwidth]{AutoEncoder_blank.png}
            \includegraphics<2>[width=\textwidth]{AutoEncoder_In.png}
            \includegraphics<3>[width=\textwidth]{AutoEncoder_Out.png}
            \includegraphics<4->[width=\textwidth]{AutoEncoder_Reg.png}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{Pick Our Latent Space Size Carefully}
    \includegraphics[width=\textwidth]{AE-MNIST.png}
\end{frame}

\begin{frame}
    \frametitle{The BIG Problem!}
    \center We can't generate new and unique samples!
\end{frame}

\begin{frame}
    \frametitle{Variational Autoencoder (VAE)}
    \begin{itemize}
        \item We need a way to generate \textbf{new} samples that aren't seen in
            the dataset.
        \item Need to add some variance and noise (make non-determanistic).
        \item Still have to be able to do back propagation.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{VAE: Breaking Down the Problem}
    \begin{itemize}
        \item<1-> Suppose there is some hidden (latent) variable $z$ that produces
            observation $x$, $p(z|x)$. \textbf{We want to learn this.}
        \item<2-> $p(z|x) = \frac{p(x|z)p(z)}{p(x)}$
        \item<3-> $p(x) = \int p(x|z)p(z)dz$ (intractable!)
        \item<4-> We can approximate $p(z|x)$ with another distribution $q(z|x)$
            that is tractable.
        \item<5-> We'll then need to measure the difference between $p$ and $q$.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Variational Autoencoder (VAE)}
    \includegraphics[width=\textwidth]{VAE.png}
\end{frame}

\begin{frame}
    \frametitle{Variational Autoencoder (VAE)}
    \begin{columns}
        \begin{column}{0.60\paperwidth}
            \begin{itemize}
                \item<1-> Encoder computes $p_\phi(z|x)$ \\(reconstruction loss, like
                    autoencoder)
                \item<2-> Decoder computes $q_\theta(x|z)$ \\(regularization term)
                \item<3-> $L(\phi,\theta,x) = ||x - \hat{x}||^2 + D(p_\phi(z|x)
                    || p(x))$
            \end{itemize}
        \end{column}
        \begin{column}{0.40\paperwidth}
            \includegraphics[width=\textwidth]{VAE.png}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{(VAE) Regularization Term}
    \begin{columns}
        \begin{column}{0.60\paperwidth}
            \begin{itemize}
                \item<1-> $L(\phi,\theta,x) = ||x - \hat{x}||^2 + D(p_\phi(z|x)
                    || p(x))$
                \item<2-> We are using the KL-Divergence between the
                    \textit{inferred latent distribution} ($p_\phi(z|x)$) and
                    the \textit{fixed prior on latent distribution} ($p(z)$).
                \item<3-> What prior? Why not Gaussian? $p(z) =
                    \mathcal{N}(\mu=0, \sigma^2=1)$
                \item<4-> Encourages encoding to distribute evenly around latent
                    space and penalizes when memorizing.
                \item<4-> $D(p_\phi(z|x) || p(z)) = -\frac12\sum(\sigma_j +
                    \mu_j^2 - 1 -\log{\sigma_j})$
            \end{itemize}
        \end{column}
        \begin{column}{0.40\paperwidth}
            \includegraphics[width=\textwidth]{VAE.png}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{(VAE) Reparameterization}
    \begin{columns}
        \begin{column}{0.60\paperwidth}
            \begin{itemize}
                \item<1-> Ops! We can't backprop through this! $z$ is a
                    stochastic node.
                \item<2-> We can reparameratize.
                \item<3-> $z = \mu + \sigma \odot \varepsilon$
                \item<3-> We let $\mu$ and $\sigma$ be fixed vectors and
                    $\varepsilon \sim \mathcal{N}(0,1)$
                \item<4-> Now we can backprop through $\phi$ and $x$. 
                \item<4-> Now we can adjust $\varepsilon$ and create new images
                    similar to the ones we learned from.
            \end{itemize}
        \end{column}
        \begin{column}{0.40\paperwidth}
            \centering\includegraphics<1-2>[width=0.5\textwidth]{VAE-beforeReParam.png}
            \centering\includegraphics<3->[width=0.7\textwidth]{VAE-ReParam.png}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{Approximate Density Estimation}
    \begin{itemize}
        \item We didn't actually learn $p(x)$ but rather $q(x)$.
        \item We approximated the density of $p(x)$ with a tractable
            distribution.
        \item KL Divergence is always $\geq 0$.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Density Estimation}
    \begin{itemize}
        \item We've come close to learning density, but not exactly. 
        \item Density is \textbf{very} difficult to learn.
        \item Having true density should mean better ability to perform our
            downstream tasks (generation, density estimation, latent variable
            inference, etc)
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Change Of Variables}
    \begin{columns}
        \begin{column}{0.49\paperwidth}
            \begin{itemize}
                \item What if we just map to a different space?
                \item We'll convert one probability distribution to another
                    tractable distribution (such as a Gaussian)
            \end{itemize}
        \end{column}
        \begin{column}{0.49\paperwidth}
            \center\includegraphics[width=\textwidth]{cov.png}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{Bijection (One-to-One)}
    \hspace{-1em}\center\includegraphics[width=1.1\textwidth]{bijective.png}
\end{frame}

\begin{frame}
    \frametitle{Change Of Variables}
    \begin{itemize}
        \item<1-> $\int p(x)dx = \int q(z)dz = 1$ (Definition of PDF)
        \item<2-> $p(x) = q(z) \left | \frac{dz}{dx} \right |$
        \item<3-> $= q(f^{-1}(x))\left | \frac{df^{-1}(x)}{dx}\right |$
        \item<4-> $p(x) = q(f^{-1}(x))\left | det\frac{df^{-1}(x)}{dx} \right |$
            (using the Jacobian determinant)
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Normalizing Flow}
    \center\includegraphics[width=\textwidth]{normalizing-flow.png}
    \tiny{Source: lilianweng.github.io}
\end{frame}

\begin{frame}
    \frametitle{Normalizing Flow}
    \begin{itemize}
        \item We need our function $f(x)$ to be easily invertible
        \item The Jacobian determinant needs to be \textit{easy} to compute.
        \item BUT we get the exact log-likelihood of $p(x)$ (tractable) and we
            can train our model on the NLL \\$\mathcal{L}(D) = -\frac{1}{|D|}
            \sum\limits_{x\in D} log{p(x)}$
    \end{itemize}
\end{frame}
